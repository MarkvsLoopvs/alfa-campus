{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3670e40f",
   "metadata": {},
   "source": [
    "# ALFABANK CAMPUS - Card transactions prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae34e09",
   "metadata": {},
   "source": [
    "Одним из самых ценных источников информации о клиенте являются данные о банковских транзакциях. В этом соревновании участникам предлагается предсказать будущие траты клиента, используя информацию о совершенных тратах.\n",
    "Данные представлены в виде массивов MCC кодов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ecf6a",
   "metadata": {},
   "source": [
    "## Импорты и загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9158a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import statistics\n",
    "from scipy import linalg\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b27178",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_train = pd.read_csv('/home/aart/datasets/alfa/df_train.csv', sep=';')\n",
    "    df_test = pd.read_csv('/home/aart/datasets/alfa/df_test.csv', sep=';')\n",
    "except:\n",
    "    url_test = \"https://raw.githubusercontent.com/MarkvsLoopvs/alfa-campus/main/df_test.csv\"\n",
    "    url_train = \"https://raw.githubusercontent.com/MarkvsLoopvs/alfa-campus/main/df_train.csv\" \n",
    "    #в репозитории находятся только csv файлы, кода и ноутбуков там нет\n",
    "    df_train = pd.read_csv(url_train, sep=';')\n",
    "    df_test = pd.read_csv(url_test, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65f4fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Data'] = df_train.Data.apply(lambda s: list(map(int, s.split(','))))\n",
    "df_train['Target'] = df_train.Target.apply(lambda s: list(map(int, s.split(','))))\n",
    "df_test['Data'] = df_test.Data.apply(lambda s: list(map(int, s.split(','))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f47f78",
   "metadata": {},
   "source": [
    "## Функции метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec2fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ea101b",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec33e212",
   "metadata": {},
   "source": [
    "### Базовая информация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01327f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Data</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[4814, 4814, 6010, 6011, 4814, 6011, 6011, 481...</td>\n",
       "      <td>[4814, 4814, 4814, 4814, 5411, 4814, 4814, 481...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[6011, 6011, 6011, 6011, 6011, 6011, 6011, 481...</td>\n",
       "      <td>[4814, 6011, 4814, 6011, 4814, 4814, 6011, 481...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[8021, 6011, 6011, 6010, 4829, 4814, 6011, 601...</td>\n",
       "      <td>[6011, 6011, 6010, 4829, 4829, 6010, 6011, 601...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[4814, 6011, 4814, 4814, 4814, 6011, 6011, 569...</td>\n",
       "      <td>[6011, 6011, 6010, 6011, 6011, 4814, 4814, 601...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[4814, 4814, 4814, 4814, 4814, 4814, 5946, 481...</td>\n",
       "      <td>[5499, 6011, 4814, 4829, 5200, 5411, 5499, 591...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               Data  \\\n",
       "0   0  [4814, 4814, 6010, 6011, 4814, 6011, 6011, 481...   \n",
       "1   1  [6011, 6011, 6011, 6011, 6011, 6011, 6011, 481...   \n",
       "2   2  [8021, 6011, 6011, 6010, 4829, 4814, 6011, 601...   \n",
       "3   3  [4814, 6011, 4814, 4814, 4814, 6011, 6011, 569...   \n",
       "4   4  [4814, 4814, 4814, 4814, 4814, 4814, 5946, 481...   \n",
       "\n",
       "                                              Target  \n",
       "0  [4814, 4814, 4814, 4814, 5411, 4814, 4814, 481...  \n",
       "1  [4814, 6011, 4814, 6011, 4814, 4814, 6011, 481...  \n",
       "2  [6011, 6011, 6010, 4829, 4829, 6010, 6011, 601...  \n",
       "3  [6011, 6011, 6010, 6011, 6011, 4814, 4814, 601...  \n",
       "4  [5499, 6011, 4814, 4829, 5200, 5411, 5499, 591...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[4814, 4814, 6011, 6011, 6010, 6011, 6011, 481...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[6010, 6011, 6010, 5411, 5411, 5977, 6011, 601...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[4814, 6011, 5251, 6011, 7832, 5641, 5814, 482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[6011, 4722, 4722, 4722, 4814, 6011, 6011, 482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[4814, 4814, 4814, 6011, 4814, 4814, 4814, 481...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               Data\n",
       "0   0  [4814, 4814, 6011, 6011, 6010, 6011, 6011, 481...\n",
       "1   1  [6010, 6011, 6010, 5411, 5411, 5977, 6011, 601...\n",
       "2   2  [4814, 6011, 5251, 6011, 7832, 5641, 5814, 482...\n",
       "3   3  [6011, 4722, 4722, 4722, 4814, 6011, 6011, 482...\n",
       "4   4  [4814, 4814, 4814, 6011, 4814, 4814, 4814, 481..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.head(), df_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f69ab19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7033, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(7033, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.shape, df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "633bb121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id         int64\n",
       "Data      object\n",
       "Target    object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Id       int64\n",
       "Data    object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.dtypes, df_test.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd277dc",
   "metadata": {},
   "source": [
    "### Длины массивов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04cedc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for i in range(len(df_train)):\n",
    "    lengths.append(len(df_train.Data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f1b5f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кратчайший массив в столбце df_train.Data: 40\n",
      "Длиннейший массив в столбце df_train.Data: 21101\n",
      "Средняя длинна массива в столбце df_train.Data: 473.3229062988767\n",
      "Медианная длина массива массива в столбце df_train.Data: 336.0\n"
     ]
    }
   ],
   "source": [
    "print('Кратчайший массив в столбце df_train.Data:', min(lengths))\n",
    "print('Длиннейший массив в столбце df_train.Data:', max(lengths))\n",
    "print('Средняя длинна массива в столбце df_train.Data:', np.mean(lengths))\n",
    "print('Медианная длина массива массива в столбце df_train.Data:', np.median(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c3e4be",
   "metadata": {},
   "source": [
    "Наблюдаем, что данные для обучения крайне неоднородны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bb88fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_test = []\n",
    "for i in range(len(df_test)):\n",
    "    lengths_test.append(len(df_test.Data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22f30e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кратчайший массив в столбце df_test.Data: 40\n",
      "Длиннейший массив в столбце df_test.Data: 88771\n",
      "Средняя длинна массива в столбце df_test.Data: 476.7561495805488\n",
      "Медианная длина массива массива в столбце df_test.Data: 344.0\n"
     ]
    }
   ],
   "source": [
    "print('Кратчайший массив в столбце df_test.Data:', min(lengths_test))\n",
    "print('Длиннейший массив в столбце df_test.Data:', max(lengths_test))\n",
    "print('Средняя длинна массива в столбце df_test.Data:', np.mean(lengths_test))\n",
    "print('Медианная длина массива массива в столбце df_test.Data:', np.median(lengths_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f913f3",
   "metadata": {},
   "source": [
    "Ситуация в тестовом датафрейме не лучше. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893d5240",
   "metadata": {},
   "source": [
    "### МСС-коды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "411b0660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6011    700677\n",
       "6010    490602\n",
       "4814    473396\n",
       "5411    472408\n",
       "4829    307388\n",
       "Name: Data, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_codes = df_train.Data.explode().value_counts()\n",
    "train_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c352187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных кодов в df_train.Data: 184\n"
     ]
    }
   ],
   "source": [
    "print('Уникальных кодов в df_train.Data:', len(train_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "043c8d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6011    694281\n",
       "6010    519030\n",
       "4814    483439\n",
       "5411    467328\n",
       "4829    304314\n",
       "Name: Data, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_codes = df_test.Data.explode().value_counts()\n",
    "test_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b533aa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных кодов в df_test.Data: 184\n"
     ]
    }
   ],
   "source": [
    "print('Уникальных кодов в df_test.Data:', len(test_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b34ffe",
   "metadata": {},
   "source": [
    "Тренировочный и тестовый датафрейм делят множество MCC кодов. Топ-5 популярнейших кодов также совпадает."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e07b8",
   "metadata": {},
   "source": [
    "## Первый подход - цепи Маркова"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e3db8c",
   "metadata": {},
   "source": [
    "Первая идея пришедная мне на ум - использовать цепи Маркова. Assumption был следущий - пользователи в целом должны следовать какой-то рутине - снял деньги в банкомате, купил продуктов, заправил машину, etc. К тому же, рутина распространяется не только на последовательности событий, но и на поле возможных трат. Другими словами, экзотические и необычные траты редки, следовательно пренебрегаемы, следовательно не должны сильно влиять на метрику. Чтобы в этом убедиться, напишем функцию для вычислений переходных матриц."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7417d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(transitions):\n",
    "    n = 1+ max(transitions) # количество состояний (в данном случае - уникальных MCC-кодов)\n",
    "    M = np.zeros((n,n)) # инициализация матрицы \n",
    "    \n",
    "    # счетчик переходов между состояними \n",
    "    for (i,j) in zip(transitions,transitions[1:]):\n",
    "        M[i,j] += 1\n",
    "\n",
    "    # перевод в вероятности\n",
    "    for row in M:\n",
    "        s = sum(row)\n",
    "        if s > 0:\n",
    "            row[:] = [f/s for f in row]\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8360d9e",
   "metadata": {},
   "source": [
    "Видим в переходной матрице некоторые довольно большие значения. Попробуем делать на их основе предсказания (цепи)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02f87636",
   "metadata": {},
   "outputs": [],
   "source": [
    "mchains=[]\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "    df_train.Data[i], label = pd.factorize(df_train.Data[i])  \n",
    "    m = transition_matrix(df_train.Data[i])\n",
    "    \n",
    "    num_iterations = 10\n",
    "    # initialize the Markov Chain\n",
    "    mc = np.zeros(num_iterations).astype(int)\n",
    "    mc[0] = df_train.Data[i][-1]\n",
    "\n",
    "    # iterate to generate the markov chain\n",
    "    for j in range(1,num_iterations):\n",
    "        mc[j] = np.argmax(np.random.multinomial(1,m[mc[j-1],:]))\n",
    "    \n",
    "    \n",
    "    df_train.Data[i] = label[df_train.Data[i]]\n",
    "    mchains.append(label[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ec87f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mchains)):\n",
    "    mchains[i] = list(mchains[i])\n",
    "    \n",
    "df_train['Predicted'] = mchains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "085538c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Таргет по первому массиву: [4814, 4814, 4814, 4814, 5411, 4814, 4814, 4814, 4814, 4814]\n",
      "Предсказание по первому массиву: [4814, 5411, 6011, 6011, 6011, 5311, 4814, 6011, 4814, 6011]\n"
     ]
    }
   ],
   "source": [
    "print('Таргет по первому массиву:', df_train['Target'][0])\n",
    "print('Предсказание по первому массиву:', df_train['Predicted'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1cdd219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Таргет по второму массиву: [4814, 6011, 4814, 6011, 4814, 4814, 6011, 4814, 6011, 4814]\n",
      "Предсказание по второму массиву: [6011, 4814, 4814, 4814, 6011, 4814, 6011, 4814, 6011, 4814]\n"
     ]
    }
   ],
   "source": [
    "print('Таргет по второму массиву:', df_train['Target'][1])\n",
    "print('Предсказание по второму массиву:', df_train['Predicted'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402a732",
   "metadata": {},
   "source": [
    "Выглядит сносно. Но как оказывается этот подход не бьет даже **первое наивное** решение из бейзлайна:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac05dda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1860911316040706"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(df_train.Target,df_train.Predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1abe9e",
   "metadata": {},
   "source": [
    "## Дальнейшие действия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fe8360",
   "metadata": {},
   "source": [
    "После такого низкого результата при казалось бы довольно неплохих на вид предсказаниях сильно расстроили и озадачили меня. Я начал размышлять и искать информацию - в первую очередь в материалах приложенных к самому заданию. Вскоре дошли руки и до досконального чтения приложенной статьи на хабре. И после ее прочтения я задумался - метрики ap@k и map@k используются в задачах ранжирования - например в recommendation engine'ах и т.п. Но ведь данная задача задачей ранжирования не является! Из следующей [статьи](https://habr.com/ru/companies/vk/articles/461927/) на хабре:\n",
    "\n",
    "\"Что подразумевается под задачей ранжирования? Представим, что в обучающей выборке есть какое-то множество запросов, для которых известен порядок документов по релевантности. Например, вы знаете, какой документ самый релевантный, какой второй по релевантности и т.д. И вам нужно восстановить такой порядок для всей генеральной совокупности. То есть для всех запросов из генеральной совокупности на первое место поставить самый релевантный документ, а на последнее — самый нерелевантный.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c0038e",
   "metadata": {},
   "source": [
    "Но ведь нам нужно предсказать совсем не это, а последовательность последующих 10 mcc-кодов. Эти коды:\n",
    "* а) Могут повторяться, и скорее всего будут это делать.\n",
    "* б) Остаются релевантными постоянными. После того как пользователь купит продукты в магазине, это вовсе не означает что пользователь никогда не купит продукты в магазине."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1719f86e",
   "metadata": {},
   "source": [
    "Но в чем же именно проблема? Говорить про некорректность метрики можно сколько угодно, но что же приводит к низким результатам казалось бы неплохих решений? На мой взгляд, к этому приводит однин if-стейтмент из расчета  ap@k:\n",
    "\n",
    "* for i, p in enumerate(predicted):\n",
    "* if p in actual **and p not in predicted[:i]:**\n",
    "* num_hits += 1.0\n",
    "* score += num_hits / (i+1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d6dac1",
   "metadata": {},
   "source": [
    "Таким образом, метрика **никак не поощряет** корректно угаданные позиции mcc-кодов, если такой же код уже был указан раннее. Но если мы посмотрим на массивы в столбце Target, мы увидим что mcc-коды в нем повторяются **постоянно**. Это имеет катастрофические последствия для моделей, которые действительно ищут какие-то закономерности, вроде тех же цепей Маркова и некоторых других, которых я обсужу в конце ноутбука. Что же поощряет эта метрика? Как мне кажется - максимальное разнообразие предиктов. Чем разнообразнее предикты - тем больше вероятность, что вам повезет угадать уникальный код и увеличить метрику."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2258c6a1",
   "metadata": {},
   "source": [
    "Подводя итоги, задача является скорее задачей **seq2seq**, и требует иных метрик для оценки результатов. Но раз в задаче требуется оптимизация под map@k, то так тому и быть. Моей следующей идеей было:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070384ba",
   "metadata": {},
   "source": [
    "## Оптимизация бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a870f",
   "metadata": {},
   "source": [
    "Решение бейзлайн-2 выдает весьма неплохие результаты, по-крайней мере по сравнению с имплементированными мной цепями Маркова. Так же во время активной фазы решения задачи активно обсуждался следующий результат вызова функции map@k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31de0677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3754930723415012"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(df_train.Target, df_train.Target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f5ce82",
   "metadata": {},
   "source": [
    "Таким образом (и я понимаю что говорить так некорректно), можно взять этот результат вызова mapk за бенчмарк со 100№ \"точностью\", что значит что у второго бейзлайна \"точность\" 0.32/0.37 = 86%+!. Весьма впечатляет. Что можно сделать чтобы ее улучшить?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048cc93d",
   "metadata": {},
   "source": [
    "### Расширить выборку, по которым вычисляются популярные транзакции."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb76f82",
   "metadata": {},
   "source": [
    "Я пробовал разные комбинации и пермутации - основывать данные только на df_train.Data, только на df_train.Target, только на df_test.Data, на их сочетаниях. Лучшие результаты для меня показала следующая выборка: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8e59923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6011    1394958\n",
       "6010    1009632\n",
       "4814     956835\n",
       "5411     939736\n",
       "4829     611702\n",
       "5499     328357\n",
       "5541     138904\n",
       "5912     130783\n",
       "5331     125113\n",
       "5812     105092\n",
       "Name: Data, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_sample = pd.concat([df_train['Data'], df_test['Data']])\n",
    "improved_top10 = improved_sample.explode().value_counts().head(10)\n",
    "improved_top10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd11e83",
   "metadata": {},
   "source": [
    "Также функция из бейзлайн 2 вычисляет самые популярные транзакции отдельных пользователей по всему массиву их исторических данных. С этим я тоже решил поэкспериментировать, и успешно. Как мы увидели на этапах EDA, длиннейший массив в тренировочных данных составляет 21101 позиций, а в тестовых данных - **88771**. Логично предположить, что для таких огромных массивов данных, паттерны поведения пользоваталей меняются. Допустим, человек совершает 10 транзакций в день. Такая оценка мне кажется даже не очень консервативной. Тогда данные до 88771 транзакций соответствуют 88771/10/365 = 24+ **лет** истории транзакций. Очевидно, что привычки у человека за такой срок поменяются. Так что мной было решено брать данные не по всем транзакциям, а последним нескольким *N* транзакциям. Мне кажется такой вывод был оправдан, и он улучшил мой результат. Еще одной идеей было поиграться с другим параметром функции - drop_from. Он отвечает за своеобразный \"порог вхождения\" в топ популярных транзакций пользователя. И, разумеется не стоит забывать вывод из предыдушего пункта - а именно, нам нужно поощрять максимальное разнообразие. Как этого достичь? Не допускать повторений. Функция из бейзлайна-2 может замешать к нам в предикты коды, которые уже были угаданы, если множество \"самые популярные транзакции пользователя\" и множество \"самые популярные транзакции вообще\" пересекаются. Условие на неповторение прописывается простым if-стейтментом. \n",
    "Таким образом, моя финальная функция выглядела так."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10044115",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_last = 0\n",
    "optimal_drop_from = 0\n",
    "\n",
    "def get_top_codes_improved(transactions, last=optimal_last, top_n=10, drop_from=optimal_drop_from):\n",
    "    transactions_stats = sorted(\n",
    "        Counter(transactions[-last:]).items(),\n",
    "        key=lambda x: x[1], \n",
    "        reverse=True\n",
    "    )[:top_n] #здесь все по старому, кроме использования последних last = optimal_last транзакций\n",
    "    \n",
    "\n",
    "    top_codes = [mcc_code for (mcc_code, count) in transactions_stats if count >= drop_from]\n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    while len(top_codes) < 10:\n",
    "        if improved_top10.index[i] not in top_codes: \n",
    "            top_codes.append(improved_top10.index[i])\n",
    "        i += 1                              #простой while цикл и if-statement следящий за разнообразием\n",
    "    \n",
    "    return top_codes[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9763a72",
   "metadata": {},
   "source": [
    "Найти лучшие oprimal_last и optimal_drop_from можно просто циклами. Мне нравится думать, что это примитивный gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf69ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_mapk=0\n",
    "#best_opt_l=0\n",
    "#best_opt_drfr=0\n",
    "\n",
    "#for optimal_last in range(1,1000):\n",
    "#    for optimal_drop_from in range(1,11):\n",
    "#        df_train['Predicted'] = df_train['Data'].apply(get_top_codes_improved)\n",
    "#        if (mapk(df_train['Target'], df_train['Predicted']))>best_mapk:\n",
    "#            optimal_last=best_opt_l\n",
    "#            optimal_drop_from=best_opt_drfr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352290d4",
   "metadata": {},
   "source": [
    "Код закомментирован, так как вложенный цикл исполняется довольно медленно. Но он полностью воспроизводим. Лучшие результаты полученные в итоге - optimal_last=195 и oprimal_drop_from=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "275abf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_codes_improved(transactions, last=195, top_n=10, drop_from=2):\n",
    "    transactions_stats = sorted(\n",
    "        Counter(transactions[-last:]).items(),\n",
    "        key=lambda x: x[1], \n",
    "        reverse=True\n",
    "    )[:top_n] \n",
    "    \n",
    "\n",
    "    top_codes = [mcc_code for (mcc_code, count) in transactions_stats if count >= drop_from]\n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    while len(top_codes) < 10:\n",
    "        if improved_top10.index[i] not in top_codes: \n",
    "            top_codes.append(improved_top10.index[i])\n",
    "        i += 1                             \n",
    "    \n",
    "    return top_codes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3e19dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33400263271335356"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Predicted'] = df_train['Data'].apply(get_top_codes_improved)\n",
    "mapk(df_train['Target'], df_train['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93268383",
   "metadata": {},
   "source": [
    "Результат mapk=0.334 на тренировочном датафрейме соответствует моему лучшему результату на лидерборде в 0.294"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78d0c58",
   "metadata": {},
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7963f4b",
   "metadata": {},
   "source": [
    "До сих пор убежден, что выбранная метрика некоррекнта для поставленной задачи seq2seq, и что все топовые решения по лидерборду в той или иной степени - оптимизация бейзлайн-2. Остаются два вопроса:\n",
    "* Как бы я решал эту задачу на самом деле? Первым делом я бы имплементировал цепи Маркова, что и было сделано. Если бы решение не показало должных результатов, я бы рассматривал эту задачу как seq2seq. Следующими шагами было бы применение RNN - LTSM или GRU. Если бы и это не дало должных результатов - можно бы было токенизировать мсс-коды и решать эту задачу словно NLP - векторизация, трансформеры, и т.п.\n",
    "* Какая метрика должна была бы быть использована? Я не знаю. Может быть какая-нибудь вариация MAPE, или вообще просто задефайнить precision/recall под эту задачу. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be88ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
